\section{Existing methods}

In this chapter we will talk about various approaches to object recognition through astronomical images or features extracted from them. We will focus on two main things: type of data and proposed method. 

\subsection{On-orbit recognition of resident space objects by using star trackers}
The main goal of the article \cite{SPILLER2020478} was to evaluate the possibility of using star trackers to track resident space objects in space. For this purpose, they developed an algorithm that could operate on-board with limited computational performance and memory.

With this in mind, the developed algorithm could not be based on machine learning as this would be computationally demanding. The algorithm is therefore based on simple tasks such as thresholding, clustering and computation of length, speed and density of each object as well as minimal distance or relative position between objects. 

\subsubsection{Data}
In order to test the proposed algorithm, synthetic images needed to be generated using their own star-tracker hardware simulator. 
The simulator consists of two modules:

\begin{itemize}
    \item Sky and spacecrafts input generator
    \item High-fidelity image generator
\end{itemize}

The goal of the first block is to simulate the sky, stars and RSOs. The sky simulation is performed using star catalog, while considering the position and orientation of the sensor as well as optical and geometric characteristics. Similar procedure is followed when simulating real RSOs, but using the catalog with orbiting RSOs instead of star catalog. Another way of simulating RSOs is to use grid method, which simulates fictious RSOs. %The output is the list of stars and RSOs with its magnitudes and positions on the image. 

The second block is used to make the image realistic. The block receives the list of stars and RSOs with their position and magnitude. Using this data as well as some additional information regarding noises, optical, geometrical and electronic characteristics of the sensor, the block produces high fidelity synthetic images. 


\subsubsection{Method}
The first step of the algorithm is to identify objects of interest from the background. After the identification of objects is complete, list of objects and their positions is produced for every image. 
The algorithm is then given pairs of images and compares each object on the first image to each object in the second image. Based on some predetermined conditions regarding their position, distance, velocity and density, objects are matched. This means that the object on the first image is the same object on the second image. The algorithm performs this comparison for series of pairs of images and as a result the object is being tracked.


\subsubsection{Conclusion}
This method was mainly developed to track moving objects in space-based observations. In this situation, RSOs usually appear as streaks. Therefore this algorithm was optimized for this scenario. However this poses as disadvantage since point-like objects are not recognized well and diffuse sources are considered background noise. 

%It is also important to mention, that the algorithm was developed in order to track streaks on the image. It does not recognize the type of the tracked object in any way. 

% tu mozno napisat to nejak inak, alebo nieco pridat
The main idea from the article that benefits this thesis, is to use high-fidelity synthetic images to train the proposed neural network. 
 

\subsection{Galaxy morphology classification using automated machine learning} 


The aim of the article \cite{REZA2021100492} was to test multiple machine learning algorithms to classify galaxies into four types. The study was conducted in order to asses the possibility of using ML for future surveys. 

\subsubsection{Data}
Dataset contained more than 304 000 samples of galaxies of different types (spirals, ellipticals, mergers and stars). Feature vectors were obtained from SDSS (Sloan Digital Sky Survey) and their extraction wasn't explained since that is not the main subject of the article. Feature vector included features such as fiber, model and Petrosian colours, axis ratio, degree of ellipticity and others. Explanation of each feature is provided in the mentioned article \cite{REZA2021100492} and will not be done here since they are not relevant to this thesis. 

\subsubsection{Method}
Five different ML methods were chosen for the purpose of this article - Decision trees, Random Forest, ExtraTrees, K-nearest neighbours and Artificial Neural Network. Before the data was fed to any model, PCA was performed on feature vectors to reduce their dimensionality. As a result, 25 most significant features were used from the original feature vector of size 62. As usual, models were trained on training set and hyperparameters were tuned on separate validation set. 

\subsubsection{Conclusion}
Evaluating the models on testing set and comparing the accuracy showed that ANN had the best results. Even though the overall accuracy of the ANN was the best, the accuracy of minority class samples showed poor results. In this case ensemble methods like combination of ExtraTrees with Random Forest performed much better. In conclusion, we can say that using balanced dataset with large amount of samples could prove to be useful when working with ANN. 


\subsection{Applications of neural networks to object detection and star/galaxy classification}
%https://academic.oup.com/mnras/article/319/3/700/1073630?login=false
The main idea of this article \cite{Andreon2000} was to present the developed package called Neural extractor (NExt), which can perform object detection and star/galaxy classification. The authors used three different NNs for each specific task: data reduction, detection and classification. 

\subsubsection{Data}
For the training, validation and testing, the subset of the IP92  catalogue \cite{1992ApJS} was used. To train the detection part of the algorithm, the best solution was to use around 10 subimages 50x50 pixels wide. To test the performance of the detection and classification networks, 4819 and 460 objects from the catalogue were chosen, respectively.

\subsubsection{Method}
The first step of the package included the detection of desired objects. This task was performed as classification of pixels into background and object class. First, the non-linear PCA NN was applied to the image, which reduced the redundant information in nearby pixels. Transformed values of the pixels were then fed to unsupervised NN. Multiple different models were tested and the best performing one was multi-layer neural gas network with a running window of size 3 or 5. 
The aim of this network was to classify pixels into background or object class. This was done in unsupervised matter and the network has split pixels into multiple classes. One of the classes could be described as a background, whereas the others described different kinds of astronomical objects and were later merged together to form an object class. After the segmentation, the overlapping objects were detected and deblended.

Second step included feature extraction and the star/galaxy classification. Considering feature extraction, multiple features were measured and through the sequential backward elimination strategy, the best performing ones were selected. These features were then used to train MLP to perform the final task of star/galaxy classification. 

\subsubsection{Conclusion}
To test the performance of the proposed method, authors compared results to the best performing package at the time (SExtractor \cite{sextractor}). Considering the detection phase of the algorithm, the proposed method was as effective as the SExtractor in the detection of true objects. For the classification phase, the NExt performed better than the SExtractor, with only 28 errors compared to 41 for the SExtractor from the total of 480 objects. 

It wasn't explicitly mentioned in the article but according to pictures this method considers only point-like appearence of the stars. This poses as a huge disadvantage in our case since the space debris usually appear as streaks during the sidereal tracking.  


\subsection{Deblending and classifying astronomical sources with Mask R-CNN deep learning}





\subsection{Conclusion}

Many of the approaches that uses NN for classification of objects use already extracted features from the image. These features are obtained from the database but the proccess of the extraction is not defined in the articles. Another common approach was to use predefined set of features, which are then measured using traditional methods. For this reason, majority of articles choose to use MLP when designing the architecture of NN. However in our case, we decided to extract features as well as classify objects using one convolutional neural network. 

Each article benefits the thesis in a different way. The generation of synthetic images was inspired by the article \cite{SPILLER2020478}, where they used different kinds of defects and noises to make the images as realistic as possible.  
Based on different ML models tested in \cite{REZA2021100492}, we decided to use the neural network, which had the best results. It is also important to train with balanced dataset, to ensure a good performance of the NN. 
The research in \cite{Andreon2000} showed that 50x50 pixels wide image is the optimal size of image for one object to be classified. %% dokoncit


